{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.neighbors\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import imageio\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Dropout, Activation, MaxPooling2D, Conv2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import locale\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "      <th>images</th>\n",
       "      <th>images_resized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0002054</td>\n",
       "      <td>ISIC_0031685</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>50.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>..\\dataset\\HAM10000_images_part_2\\ISIC_0031685...</td>\n",
       "      <td>Melanocytic nevi</td>\n",
       "      <td>4</td>\n",
       "      <td>[253, 190, 198, 255, 189, 199, 254, 192, 197, ...</td>\n",
       "      <td>[254, 193, 198, 254, 194, 200, 254, 195, 203, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0001690</td>\n",
       "      <td>ISIC_0032361</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>50.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>..\\dataset\\HAM10000_images_part_2\\ISIC_0032361...</td>\n",
       "      <td>Melanocytic nevi</td>\n",
       "      <td>4</td>\n",
       "      <td>[248, 173, 180, 245, 174, 182, 247, 171, 181, ...</td>\n",
       "      <td>[247, 172, 182, 245, 171, 179, 246, 172, 181, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0005332</td>\n",
       "      <td>ISIC_0027389</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>..\\dataset\\HAM10000_images_part_1\\ISIC_0027389...</td>\n",
       "      <td>Melanocytic nevi</td>\n",
       "      <td>4</td>\n",
       "      <td>[201, 108, 116, 201, 103, 118, 208, 108, 118, ...</td>\n",
       "      <td>[204, 108, 117, 204, 108, 116, 204, 111, 116, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000078</td>\n",
       "      <td>ISIC_0030853</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>..\\dataset\\HAM10000_images_part_2\\ISIC_0030853...</td>\n",
       "      <td>Melanocytic nevi</td>\n",
       "      <td>4</td>\n",
       "      <td>[222, 138, 162, 223, 139, 163, 225, 141, 165, ...</td>\n",
       "      <td>[222, 140, 162, 227, 143, 165, 229, 145, 168, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0004764</td>\n",
       "      <td>ISIC_0025270</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>..\\dataset\\HAM10000_images_part_1\\ISIC_0025270...</td>\n",
       "      <td>Melanocytic nevi</td>\n",
       "      <td>4</td>\n",
       "      <td>[218, 121, 140, 218, 120, 135, 220, 122, 137, ...</td>\n",
       "      <td>[218, 121, 134, 217, 118, 132, 218, 119, 131, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id  dx    dx_type   age     sex localization  \\\n",
       "0  HAM_0002054  ISIC_0031685  nv  follow_up  50.0  female      abdomen   \n",
       "1  HAM_0001690  ISIC_0032361  nv  follow_up  50.0  female      abdomen   \n",
       "2  HAM_0005332  ISIC_0027389  nv  follow_up  45.0  female      abdomen   \n",
       "3  HAM_0000078  ISIC_0030853  nv  follow_up  35.0    male      abdomen   \n",
       "4  HAM_0004764  ISIC_0025270  nv  follow_up  60.0    male      abdomen   \n",
       "\n",
       "                                                path         cell_type  \\\n",
       "0  ..\\dataset\\HAM10000_images_part_2\\ISIC_0031685...  Melanocytic nevi   \n",
       "1  ..\\dataset\\HAM10000_images_part_2\\ISIC_0032361...  Melanocytic nevi   \n",
       "2  ..\\dataset\\HAM10000_images_part_1\\ISIC_0027389...  Melanocytic nevi   \n",
       "3  ..\\dataset\\HAM10000_images_part_2\\ISIC_0030853...  Melanocytic nevi   \n",
       "4  ..\\dataset\\HAM10000_images_part_1\\ISIC_0025270...  Melanocytic nevi   \n",
       "\n",
       "   cell_type_idx                                             images  \\\n",
       "0              4  [253, 190, 198, 255, 189, 199, 254, 192, 197, ...   \n",
       "1              4  [248, 173, 180, 245, 174, 182, 247, 171, 181, ...   \n",
       "2              4  [201, 108, 116, 201, 103, 118, 208, 108, 118, ...   \n",
       "3              4  [222, 138, 162, 223, 139, 163, 225, 141, 165, ...   \n",
       "4              4  [218, 121, 140, 218, 120, 135, 220, 122, 137, ...   \n",
       "\n",
       "                                      images_resized  \n",
       "0  [254, 193, 198, 254, 194, 200, 254, 195, 203, ...  \n",
       "1  [247, 172, 182, 245, 171, 179, 246, 172, 181, ...  \n",
       "2  [204, 108, 117, 204, 108, 116, 204, 111, 116, ...  \n",
       "3  [222, 140, 162, 227, 143, 165, 229, 145, 168, ...  \n",
       "4  [218, 121, 134, 217, 118, 132, 218, 119, 131, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_skin_dir = os.path.join('..','dataset')\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                 for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n",
    "\n",
    "lesion_type_dict = {\n",
    "'nv': 'Melanocytic nevi',\n",
    "'mel': 'Melanoma',\n",
    "'bkl': 'Benign keratosis-like lesions ',\n",
    "'bcc': 'Basal cell carcinoma',\n",
    "'akiec': 'Actinic keratoses',\n",
    "'vasc': 'Vascular lesions',\n",
    "'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\n",
    "\n",
    "df['path'] = df['image_id'].map(imageid_path_dict.get)\n",
    "df['cell_type'] = df['dx'].map(lesion_type_dict.get)\n",
    "df['cell_type_idx'] = pd.Categorical(df['cell_type']).codes\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['images'] = df['path'].map(lambda x: np.asarray(Image.open(x))).apply(lambda x : x.reshape(810000))\n",
    "df['images_resized'] = df['path'].map(lambda x: np.asarray(Image.open(x).resize((100,75)))).apply(lambda x : x.reshape(22500))\n",
    "\n",
    "## fill missing values with mean age\n",
    "df['age'].fillna((df['age'].mean()), inplace = True)\n",
    "\n",
    "## drop duplicates\n",
    "df = df.drop_duplicates(subset=['lesion_id'], keep = 'first')\n",
    "\n",
    "# convert categorical columns to numeric values\n",
    "df.localization = df.localization.astype('category')\n",
    "df.dx_type = df.dx_type.astype('category')\n",
    "df.sex = df.sex.astype('category')\n",
    "\n",
    "## isolate nv rows\n",
    "data_nv = df[df['dx'] == 'nv']\n",
    "\n",
    "# define scaling parameters\n",
    "scaling = 1000 / data_nv.shape[0]\n",
    "\n",
    "# stratified sampling\n",
    "rus = RandomUnderSampler(sampling_strategy={'lower extremity' : int(1224*scaling),\n",
    "                                            'trunk' : int(1153*scaling),\n",
    "                                            'back' : int(1058*scaling),\n",
    "                                            'abdomen' : int(719*scaling),\n",
    "                                            'upper extremity' : int(504*scaling) ,\n",
    "                                            'foot' : int(209*scaling),\n",
    "                                            'unknown' : int(175*scaling),\n",
    "                                            'chest' : int(112*scaling),\n",
    "                                            'face' : int(61*scaling),\n",
    "                                            'neck' : int(60*scaling),\n",
    "                                            'genital' : int(43*scaling),\n",
    "                                            'hand' : int(39*scaling),\n",
    "                                            'scalp' : int(24*scaling),\n",
    "                                            'ear' : int(19*scaling),\n",
    "                                            'acral' : int(3*scaling)+1\n",
    "                                           },\n",
    "                           random_state=None,\n",
    "                           replacement=False,\n",
    "                        )\n",
    "\n",
    "## fit strtaified sampling model\n",
    "n_x, n_y = rus.fit_resample(data_nv, data_nv['localization'])\n",
    "\n",
    "## delete nv rows from original dataset\n",
    "no_nv_data = df[df.dx != 'nv']\n",
    "\n",
    "df = pd.concat([n_x, no_nv_data], axis=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-633337079cd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(random_state=1, **kwargs):\n",
    "  '''\n",
    "  Import and merge dataframes, pass n_rows arg to pd.read_csv to get a sample dataset\n",
    "  '''\n",
    "\n",
    "  base_skin_dir = os.path.join('..','dataset')\n",
    "  imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n",
    "\n",
    "  lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "  }\n",
    "\n",
    "  df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\n",
    "\n",
    "  df['path'] = df['image_id'].map(imageid_path_dict.get)\n",
    "  df['cell_type'] = df['dx'].map(lesion_type_dict.get)\n",
    "  df['cell_type_idx'] = pd.Categorical(df['cell_type']).codes\n",
    "\n",
    "  df.dropna(inplace=True)\n",
    "\n",
    "  df['images'] = df['path'].map(lambda x: np.asarray(Image.open(x))).apply(lambda x : x.reshape(810000))\n",
    "  df['images_resized'] = df['path'].map(lambda x: np.asarray(Image.open(x).resize((100,75)))).apply(lambda x : x.reshape(22500))\n",
    "\n",
    "  return df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "  ## fill missing values with mean age\n",
    "  df['age'].fillna((df['age'].mean()), inplace = True)\n",
    "\n",
    "  ## drop duplicates\n",
    "  df = df.drop_duplicates(subset=['lesion_id'], keep = 'first')\n",
    "\n",
    "  # convert categorical columns to numeric values\n",
    "  df.localization = df.localization.astype('category')\n",
    "  df.dx_type = df.dx_type.astype('category')\n",
    "  df.sex = df.sex.astype('category')\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "balance nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_nv(df, under_sample_size):\n",
    "\n",
    "        ## isolate nv rows\n",
    "        data_nv = df[df['dx'] == 'nv']\n",
    "\n",
    "        # define scaling parameters\n",
    "        sample_size = under_sample_size\n",
    "        scaling = under_sample_size / data_nv.shape[0]\n",
    "\n",
    "        # stratified sampling\n",
    "        rus = RandomUnderSampler(sampling_strategy={'lower extremity' : int(1224*scaling),\n",
    "                                                    'trunk' : int(1153*scaling),\n",
    "                                                    'back' : int(1058*scaling),\n",
    "                                                    'abdomen' : int(719*scaling),\n",
    "                                                    'upper extremity' : int(504*scaling) ,\n",
    "                                                    'foot' : int(209*scaling),\n",
    "                                                    'unknown' : int(175*scaling),\n",
    "                                                    'chest' : int(112*scaling),\n",
    "                                                    'face' : int(61*scaling),\n",
    "                                                    'neck' : int(60*scaling),\n",
    "                                                    'genital' : int(43*scaling),\n",
    "                                                    'hand' : int(39*scaling),\n",
    "                                                    'scalp' : int(24*scaling),\n",
    "                                                    'ear' : int(19*scaling),\n",
    "                                                    'acral' : int(3*scaling)+1\n",
    "                                                   },\n",
    "                                   random_state=None,\n",
    "                                   replacement=False,\n",
    "                                )\n",
    "\n",
    "        ## fit strtaified sampling model\n",
    "        n_x, n_y = rus.fit_resample(data_nv, data_nv['localization'])\n",
    "\n",
    "        ## delete nv rows from original dataset\n",
    "        no_nv_data = df[df.dx != 'nv']\n",
    "\n",
    "        df = pd.concat([n_x, no_nv_data], axis=0)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(df, image_size = 'resized'):\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    ## Define random image modifications\n",
    "    aug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "    if image_size == 'resized':\n",
    "        target_images = 'images_resized'\n",
    "        input_size = (75,100,3)\n",
    "        df = df.drop(['images'], axis =1)\n",
    "        new_df = df.copy()\n",
    "        new_df = new_df.drop(['images_resized'], axis=1)\n",
    "\n",
    "\n",
    "    elif image_size == 'full_size':\n",
    "        target_images = 'images'\n",
    "        input_size = (450,600,3)\n",
    "        df = df.drop(['images_resized'], axis =1)\n",
    "        new_df = df.copy()\n",
    "        new_df = new_df.drop(['images'], axis=1)\n",
    "\n",
    "    ## Create np.array of augmented images from original images dataframe. Reshape to feed into dataGen\n",
    "    images_array = np.array([i.reshape(input_size) for i in df[target_images].values])\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    print(\"images_array.shape\")\n",
    "    #construct the actual Python generator, iterate over imagegenerator object\n",
    "    dataGen = aug.flow(images_array, batch_size = images_array.shape[0])\n",
    "    for i in dataGen:\n",
    "        break\n",
    "\n",
    "    ## flatten i before concatenating it into new dataframe copy\n",
    "    i = i.reshape(len(df), input_size[0]*input_size[1]*input_size[2])\n",
    "\n",
    "    ## turn i from array into list so it can be converted into pd\n",
    "    im_list = []\n",
    "    for im in i:\n",
    "        im_list.append(im)\n",
    "\n",
    "    # convert i into the pandas i_df\n",
    "    i_df = pd.DataFrame({target_images: im_list})\n",
    "\n",
    "\n",
    "    ## concatenate new_df numpy array and new augmented image array\n",
    "    com_new_df = pd.concat((new_df, i_df), axis = 1)\n",
    "    print(com_new_df)\n",
    "\n",
    "    ## vertically concatenate new dataframes\n",
    "\n",
    "    frames = [df, com_new_df]\n",
    "    df = pd.concat(frames)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageScaler():\n",
    "  def __init__(self, scaler='normalization',image_size='full_size'):\n",
    "    self.scaler=scaler\n",
    "    self.image_size=image_size\n",
    "\n",
    "  def transform(self, X, y=None):\n",
    "    if self.scaler=='normalization':\n",
    "      X['pixels_scaled'] = X.image_size.apply(lambda x: x/255)\n",
    "    if self.scaler=='standardization':\n",
    "      scaler = StandardScaler()\n",
    "      X['pixels_scaled'] = X.image_size.apply(lambda x: (x - x.mean(axis=0))/x.std(axis=0))\n",
    "    if self.scaler=='centering':\n",
    "      X['pixels_scaled'] = X.image_size.apply(lambda x: ((x - x.mean(axis=0))-(x - x.mean(axis=0)).min())/((x - x.mean(axis=0)).max()-(x - x.mean(axis=0)).min()))\n",
    "\n",
    "    return X[['pixels_scaled']]\n",
    "\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, X, y, **kwargs):\n",
    "\n",
    "        self.pipeline = None\n",
    "        self.kwargs = kwargs\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.split = self.kwargs.get(\"split\", True)\n",
    "\n",
    "        # Image dimension attributes\n",
    "        self.scaler = self.kwargs.get('scaler', 'normalization')\n",
    "        self.image_size = self.kwargs.get('image_size', 'full_size')\n",
    "        if self.image_size == 'full_size':\n",
    "          self.target_images = 'images'\n",
    "          self.input_shape = (450, 600, 3)\n",
    "        elif self.image_size == 'resized':\n",
    "          self.target_images = 'images_resized'\n",
    "          self.input_shape = (75, 100, 3)\n",
    "        self.input_dim = len(X)\n",
    "\n",
    "        # Training attributes\n",
    "        self.history = None\n",
    "        self.train_results = None\n",
    "        self.test_results = None\n",
    "\n",
    "\n",
    "    def get_estimator(self):\n",
    "        # get different models as self.model\n",
    "        if self.estimator=='baseline_model':\n",
    "            self.model = BaselineModel().merge_compile_models(input_dim=self.input_dim, input_shape=self.input_shape, num_labels=self.num_labels)\n",
    "        elif self.estimator=='tl_vgg':\n",
    "            self.model = TLModels().tl_merge_compile_models(input_dim=self.input_dim, input_shape=self.input_shape, selection='vgg16', num_labels=self.num_labels)\n",
    "        elif self.estimator=='tl_resnet':\n",
    "            self.model = TLModels().tl_merge_compile_models(input_dim=self.input_dim, input_shape=self.input_shape, selection='resnet', num_labels=self.num_labels)\n",
    "        elif self.estimator=='tl_densenet':\n",
    "            self.model = TLModels().tl_merge_compile_models(input_dim=self.input_dim, input_shape=self.input_shape, selection='densenet', num_labels=self.num_labels)\n",
    "\n",
    "\n",
    "    def set_pipeline(self):\n",
    "\n",
    "        # Define feature engineering pipeline blocks\n",
    "        self.ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "        self.rs = RobustScaler()\n",
    "        self.imsc = ImageScaler(scaler=self.scaler, image_size=self.image_size)\n",
    "\n",
    "        pipe_cat_feats = make_pipeline(self.ohe)\n",
    "        pipe_cont_feats = make_pipeline(self.rs)\n",
    "        pipe_photo_feats = make_pipeline(self.imsc)\n",
    "\n",
    "        # Define default feature engineering blocs\n",
    "        feateng_blocks = [\n",
    "            ('cat_feats', pipe_cat_feats, ['localization', 'dx_type', 'sex']),\n",
    "            ('cont_features', pipe_cont_feats, ['age']),\n",
    "            ('photo_feats', pipe_photo_feats, [self.target_images]),\n",
    "        ]\n",
    "\n",
    "        self.features_encoder = ColumnTransformer(feateng_blocks, n_jobs=None, remainder=\"drop\")\n",
    "\n",
    "        self.pipeline = Pipeline(steps=[\n",
    "            ('features', self.features_encoder)\n",
    "            ])\n",
    "\n",
    "\n",
    "    def add_grid_search(self):\n",
    "        \"\"\"\"\n",
    "        Apply Gridsearch on self.params defined in get_estimator - using RegressionHyperModel?\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    #@simple_time_tracker\n",
    "    def preprocess(self, gridsearch=False, image_type=\"full_size\"):\n",
    "        \"\"\"\n",
    "        Add time tracker - if we want?\n",
    "        \"\"\"\n",
    "        # categorise y\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "        import ipdb; ipdb.set_trace()\n",
    "        self.num_labels = len(np.unique(self.y.values))\n",
    "        self.y = ohe.fit_transform(self.y.values.reshape(-1, 1)).toarray()\n",
    "        print(\"-----------STATUS UPDATE: Y CATEGORISED'-----------\")\n",
    "\n",
    "        # scale/encode X features (metadata + pixel data) via pipeline\n",
    "        self.set_pipeline()\n",
    "        self.X = self.pipeline.fit_transform(self.X)\n",
    "\n",
    "        # convert self.X to pd.df\n",
    "        self.col_list = []\n",
    "        list_arrays = self.features_encoder.transformers_[0][1].named_steps['onehotencoder'].categories_\n",
    "        for i in list_arrays:\n",
    "            for col_name in i:\n",
    "                self.col_list.append(col_name)\n",
    "        self.col_list.append('age_scaled')\n",
    "        self.col_list.append('pixels_scaled')\n",
    "\n",
    "        self.X = pd.DataFrame(self.X, columns=self.col_list)\n",
    "        print(\"-----------STATUS UPDATE: PIPELINE FITTED'-----------\")\n",
    "\n",
    "        # create train vs test dataframes\n",
    "        if self.split:\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, random_state=1, test_size=0.3)\n",
    "\n",
    "        self.pixels_to_array(image_type=self.image_size)\n",
    "        print(\"-----------STATUS UPDATE: DATA SPLIT INTO X/Y TEST/TRAIN MET/IM'-----------\")\n",
    "\n",
    "\n",
    "    def pixels_to_array(self, image_type=\"full_size\"):\n",
    "        \"\"\"\n",
    "        Convert X_train and X_test into [X_met_train + X_im_train] and [X_met_test + X_im_test] respectively\n",
    "        \"\"\"\n",
    "        self.X_met_train = self.X_train.drop(columns=['pixels_scaled']).astype('float64')\n",
    "        self.X_met_test = self.X_test.drop(columns=['pixels_scaled']).astype('float64')\n",
    "\n",
    "        if image_type == \"full_size\":\n",
    "            self.X_im_train = np.array([i.reshape(450, 600, 3) for i in self.X_train['pixels_scaled'].values])\n",
    "            self.X_im_test = np.array([i.reshape(450, 600, 3) for i in self.X_test['pixels_scaled'].values])\n",
    "        elif image_type == \"resized\":\n",
    "            self.X_im_train = np.array([i.reshape(75, 100, 3) for i in self.X_train['pixels_scaled'].values])\n",
    "            self.X_im_test = np.array([i.reshape(75, 100, 3) for i in self.X_test['pixels_scaled'].values])\n",
    "        print(\"-----------STATUS UPDATE: PIXEL ARRAGYS EXTRACTED'-----------\")\n",
    "\n",
    "\n",
    "    #@simple_time_tracker\n",
    "    def train(self, gridsearch=False, estimator='baseline_model'):\n",
    "        # assign self.estimator as desired estimator and set self.model via get_estimator()\n",
    "        self.estimator=estimator\n",
    "        self.get_estimator()\n",
    "\n",
    "        # define es criteria and fit model\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', patience=25, verbose=1, restore_best_weights=True)\n",
    "        self.history = self.model.fit(x=[self.X_met_train, self.X_im_train], y=self.y_train,\n",
    "            validation_split=0.3,\n",
    "            epochs=200,\n",
    "            callbacks = [es],\n",
    "            batch_size=8,\n",
    "            verbose = 1)\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "      ## SEE TRAINING MODEL ACCURACY\n",
    "      self.train_results = self.model.evaluate(x=[self.X_met_train, self.X_im_train], y=self.y_train, verbose=1)\n",
    "      print('Train Loss: {} - Train Accuracy: {}'.format(self.train_met_results[0], self.train_met_results[1]))\n",
    "      # print('Train Loss: {} - Train Accuracy: {} - Train Recall: {} - Train Precision: {}'.format(self.train_met_results[0], self.train_met_results[1], self.train_met_results[2], self.train_met_results[3]))\n",
    "\n",
    "      ## TEST DATA ACCURACY\n",
    "      self.test_results = self.model.evaluate([self.X_met_test, self.X_im_test], self.y_test, verbose=0)\n",
    "      print('Train Loss: {} - Train Accuracy: {}'.format(self.test_met_results[0], self.test_met_results[1]))\n",
    "      # print('Test Loss: {} - Test Accuracy: {} - Test Recall: {} - Test Precision: {}'.format(self.test_met_results[0], self.test_met_results[1], self.test_met_results[2], self.test_met_results[3]))\n",
    "\n",
    "\n",
    "    def plot_loss_accuracy(history):\n",
    "\n",
    "        fig, axs = plt.subplots(2)\n",
    "\n",
    "        axs[0].plot(history.history['loss'])\n",
    "        axs[0].plot(history.history['val_loss'])\n",
    "        plt.title(\"Model Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.legend(['Train', 'val_test'], loc='best')\n",
    "\n",
    "        axs[1].plot(history.history['accuracy'])\n",
    "        axs[1].plot(history.history['val_accuracy'])\n",
    "        plt.title(\"Model Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.legend(['Train', 'val_test'], loc='best')\n",
    "\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"\n",
    "        Save the model into a .joblib\n",
    "        \"\"\"\n",
    "        joblib.dump(self.pipeline, 'model.joblib')\n",
    "        print(colored(\"model.joblib saved locally\", \"green\"))\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel():\n",
    "\n",
    "    def create_mlp(self, input_dim):\n",
    "        \"\"\"\n",
    "        Create Multi-Layer Perceptron as left_hand fork of mixed neural network for numeric and categorical explanatory variables\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Dense(8, input_dim=input_dim, activation=\"relu\"))\n",
    "        model.add(Dense(4, activation=\"relu\"))\n",
    "        return model\n",
    "\n",
    "    def create_cnn(self, input_shape, filters=(16, 32, 64)):\n",
    "        \"\"\"\n",
    "        Create Convolutional Neural Network as right-hand fork of mixed neural network for pixel data\n",
    "        \"\"\"\n",
    "        # initialize the input shape and channel dimension, assuming TensorFlow/channels-last ordering\n",
    "        chanDim = -1\n",
    "\n",
    "        # define the model input\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        # loop over the number of filters\n",
    "        for (i, f) in enumerate(filters):\n",
    "            # if this is the first CONV layer then set the input appropriately\n",
    "            if i == 0:\n",
    "                x = inputs\n",
    "            # add aspects of each CONV interation: CONV => RELU => BN => POOL\n",
    "            x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "            x = Activation(\"relu\")(x)\n",
    "            x = BatchNormalization(axis=chanDim)(x)\n",
    "            x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "        # flatten then FC => RELU => BN => DROPOUT\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "\n",
    "        # apply another FC layer tto match the number of nodes coming out of the MLP\n",
    "        x = Dense(4)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        # construct the CNN and return model\n",
    "        model = Model(inputs, x)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def merge_compile_models(self, input_dim, input_shape, filters=(16, 32, 64), num_labels=7):\n",
    "        \"\"\"\n",
    "        Join forks of network to combine models for all data types\n",
    "        \"\"\"\n",
    "        # create the MLP and CNN models\n",
    "        mlp = self.create_mlp(input_dim)\n",
    "        cnn = self.create_cnn(input_shape)\n",
    "\n",
    "        # create the input to our final set of layers as the output of both the MLP and CNN\n",
    "        combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "        # add final FC layer head with 2 dense layers with final layer as the multi-classifier head\n",
    "        x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "        x = Dense(num_labels, activation=\"softmax\")(x)\n",
    "\n",
    "        # yield final model integrating categorical/numerical data and images into single diagnostic prediction\n",
    "        model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "\n",
    "        # compile the model using BCE as loss\n",
    "        opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "        model.compile(loss=\"categorical_crossentropy\",\n",
    "          optimizer=opt,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "        #NB have removed  'precision', 'f1'\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------STATUS UPDATE: DATA IMPORTED-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\john dahler\\.venvs\\lewagon\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------STATUS UPDATE: DATA CLEANED-----------\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1e1bbaeac53a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-----------STATUS UPDATE: DATA CLEANED-----------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbalance_nv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-----------STATUS UPDATE: DATA BALANCED-----------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-06aa6d0ea508>\u001b[0m in \u001b[0;36mbalance_nv\u001b[1;34m(df, under_sample_size)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m# define scaling parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0msample_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munder_sample_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mscaling\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munder_sample_size\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdata_nv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# stratified sampling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "    # Get and clean data\n",
    "    df = get_data()\n",
    "    print(\"-----------STATUS UPDATE: DATA IMPORTED-----------\")\n",
    "\n",
    "    df = clean_df(df)\n",
    "    print(\"-----------STATUS UPDATE: DATA CLEANED-----------\")\n",
    "\n",
    "    df = balance_nv(df, 1000)\n",
    "    print(\"-----------STATUS UPDATE: DATA BALANCED-----------\")\n",
    "\n",
    "    df = data_augmentation(df, image_size='resized')\n",
    "    print(\"-----------STATUS UPDATE: DATA AUGMENTED-----------\")\n",
    "\n",
    "    # Assign X and y and instanciate Trainer Class\n",
    "    X = df.drop(columns=['dx', 'lesion_id', 'image_id'])\n",
    "    y = df['dx']\n",
    "    t = Trainer(X, y, image_size='resized')\n",
    "\n",
    "    # Preprocess data: transfrom and scale\n",
    "    print(\"############  Preprocessing data   ############\")\n",
    "    t.preprocess(image_type=t.image_size)\n",
    "\n",
    "    # Train model\n",
    "    print(\"############  Training model   ############\")\n",
    "    t.train(estimator='baseline_model')\n",
    "\n",
    "    # Evaluate model on X_test/y_preds vs y_test\n",
    "    print(\"############  Evaluating model   ############\")\n",
    "    t.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
